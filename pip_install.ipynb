{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd030e21dc3ec1938ceff07fd29576d0c36cddf01a42a134a7947f9997dd77d262c",
   "display_name": "Python 3.7.9 64-bit ('ml-agents': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "30e21dc3ec1938ceff07fd29576d0c36cddf01a42a134a7947f9997dd77d262c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\nRequirement already satisfied: torch==1.4.0+cu92 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.4.0+cu92)\nRequirement already satisfied: torchvision==0.5.0+cu92 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (0.5.0+cu92)\nRequirement already satisfied: pillow>=4.1.1 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from torchvision==0.5.0+cu92) (8.0.1)\nRequirement already satisfied: six in c:\\users\\naoya\\appdata\\roaming\\python\\python37\\site-packages (from torchvision==0.5.0+cu92) (1.15.0)\nRequirement already satisfied: numpy in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from torchvision==0.5.0+cu92) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.4.0+cu92 torchvision==0.5.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.19.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\naoya\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Collecting multiprocessing\n",
      "  Using cached multiprocessing-2.6.2.1.tar.gz (108 kB)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\naoya\\Anaconda3\\envs\\ml-agents\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\naoya\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dnevafig\\\\multiprocessing\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\naoya\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dnevafig\\\\multiprocessing\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\naoya\\AppData\\Local\\Temp\\pip-pip-egg-info-few_9ly6'\n",
      "         cwd: C:\\Users\\naoya\\AppData\\Local\\Temp\\pip-install-dnevafig\\multiprocessing\\\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\naoya\\AppData\\Local\\Temp\\pip-install-dnevafig\\multiprocessing\\setup.py\", line 94\n",
      "        print 'Macros:'\n",
      "                      ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print('Macros:')?\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n",
      "Requirement already satisfied: botocore in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.20.73)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from botocore) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from botocore) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from botocore) (1.26.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\naoya\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.15.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.17.73)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.73 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from boto3) (1.20.73)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from boto3) (0.4.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from botocore<1.21.0,>=1.20.73->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from botocore<1.21.0,>=1.20.73->boto3) (1.26.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\naoya\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.73->boto3) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install multiprocessing\n",
    "!pip install botocore\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from urllib import request\n",
    "def http_download(url, path):\n",
    "    with request.urlopen(url) as f:\n",
    "        with open(path, \"wb\") as fout:\n",
    "            buf = f.read(1024)\n",
    "            while buf:\n",
    "                fout.write(buf)\n",
    "                buf = f.read(1024)\n",
    "\n",
    "from multiprocessing import Pool, Manager\n",
    "import functools\n",
    "\n",
    "def log_counts(values):\n",
    "    for k, count in values.value_counts().iteritems():\n",
    "        logging.warning(f\"{k}: {count}/{len(values)} = {count/len(values):.2f}.\")\n",
    "\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import botocore\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "def download(bucket, root, retry, counter, lock, path):\n",
    "    i = 0\n",
    "    src = path\n",
    "    dest = f\"{root}/{path}\"\n",
    "    logging.warning(\"start downloading :\" +  str(dest))\n",
    "    while i < retry:\n",
    "        try:\n",
    "            if not os.path.exists(dest):\n",
    "                s3.download_file(bucket, src, dest)\n",
    "            else:\n",
    "                logging.info(f\"{dest} already exists.\")\n",
    "            with lock:\n",
    "                counter.value += 1\n",
    "                if counter.value % 100 == 0:\n",
    "                    logging.warning(f\"Downloaded {counter.value} images.\")\n",
    "            return\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == \"404\":\n",
    "                logging.warning(f\"The file s3://{bucket}/{src} does not exist.\")\n",
    "                return\n",
    "            i += 1\n",
    "            logging.warning(f\"Sleep {i} and try again.\")\n",
    "            time.sleep(i)\n",
    "    logging.warning(f\"Failed to download the file s3://{bucket}/{src}. Exception: {e}\")\n",
    "\"\"\"\n",
    "def batch_download(bucket, file_paths, root, num_workers=4, retry=1):\n",
    "    with Pool(num_workers) as p:\n",
    "        m = Manager()\n",
    "        counter = m.Value('i', 0)\n",
    "        lock = m.Lock()\n",
    "        download_ = functools.partial(download, bucket, root, retry, counter, lock)\n",
    "        p.map(download_, file_paths)\n",
    "\"\"\"\n",
    "#直列に変更\n",
    "def batch_download(bucket, file_paths, root, num_workers=4, retry=1):\n",
    "    m = Manager()\n",
    "    counter = m.Value('i', 0)\n",
    "    lock = m.Lock()\n",
    "    for file_path in file_paths:\n",
    "        download(bucket, root, retry, counter, lock, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nbucket = \"open-images-dataset\"\\nimport pandas as pd\\nimport logging\\nimport os\\nclass_description_file = \\'./class-descriptions-boxable.csv\\' #bofore download CLI \\nclass_descriptions = pd.read_csv(class_description_file,names=[\"id\", \"ClassName\"])\\n#learn bottle data\\nclass_names = [\"Bottle\"]\\ngroup_filters = [\"\"]\\npercentages = [1.0]\\nexcluded_images = set()\\nclass_descriptions = class_descriptions[class_descriptions[\\'ClassName\\'].isin(class_names)]\\n\\nimage_files = []\\nobject_dir = \"./images\"\\nos.makedirs(object_dir, exist_ok=True)\\nfor dataset_type in [\"train\", \"validation\", \"test\"]:\\n    image_dir = os.path.join(object_dir, dataset_type)\\n\\n    #csvのダウンロード(バカ長い)\\n    os.makedirs(image_dir, exist_ok=True)\\n    annotation_file = f\"{image_dir}/{dataset_type}-annotations-bbox.csv\"\\n    if not os.path.exists(annotation_file):\\n        url = f\"https://storage.googleapis.com/openimages/2018_04/{dataset_type}/{dataset_type}-annotations-bbox.csv\"\\n        logging.warning(f\"Download {url}.\")\\n        http_download(url, annotation_file)\\n\\n    logging.warning(f\"Read annotation file {annotation_file}\")\\n    annotations = pd.read_csv(annotation_file)\\n    annotations = pd.merge(annotations, class_descriptions,left_on=\"LabelName\", right_on=\"id\",how=\"inner\")\\n    annotations = annotations.loc[annotations[\\'IsDepiction\\'] != 1, :] #?\\n\\n    filtered = []\\n    for class_name, group_filter, percentage in zip(class_names, group_filters, percentages):\\n        sub = annotations.loc[annotations[\\'ClassName\\'] == class_name, :]\\n        excluded_images |= set(sub[\\'ImageID\\'].sample(frac=1 - percentage))\\n\\n        if group_filter == \\'~group\\':\\n            excluded_images |= set(sub.loc[sub[\\'IsGroupOf\\'] == 1, \\'ImageID\\'])\\n        elif group_filter == \\'group\\':\\n            excluded_images |= set(sub.loc[sub[\\'IsGroupOf\\'] == 0, \\'ImageID\\'])\\n        filtered.append(sub)\\n\\n    annotations = pd.concat(filtered)\\n    annotations = annotations.loc[~annotations[\\'ImageID\\'].isin(excluded_images), :]\\n\\n    annotations = annotations.sample(frac=1.0)\\n\\n    logging.warning(f\"{dataset_type} bounding boxes size: {annotations.shape[0]}\")\\n    logging.warning(\"Approximate Image Stats: \")\\n    log_counts(annotations.drop_duplicates([\"ImageID\", \"ClassName\"])[\"ClassName\"])\\n    logging.warning(\"Label distribution: \")\\n    log_counts(annotations[\\'ClassName\\'])\\n\\n    logging.warning(f\"Shuffle dataset.\")\\n\\n\\n    sub_annotation_file = f\"{object_dir}/sub-{dataset_type}-annotations-bbox.csv\"\\n    logging.warning(f\"Save {dataset_type} data to {sub_annotation_file}.\")\\n    annotations.to_csv(sub_annotation_file, index=False)\\n    image_files.extend(f\"{dataset_type}/{id}.jpg\" for id in set(annotations[\\'ImageID\\']))\\nlogging.warning(f\"Start downloading {len(image_files)} images.\")\\nbatch_download(bucket, image_files, object_dir, 4, 1)\\nlogging.warning(\"Task Done.\")\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "#download open-images, make my own dataset!!!!\n",
    "\"\"\"\n",
    "bucket = \"open-images-dataset\"\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "class_description_file = './class-descriptions-boxable.csv' #bofore download CLI \n",
    "class_descriptions = pd.read_csv(class_description_file,names=[\"id\", \"ClassName\"])\n",
    "#learn bottle data\n",
    "class_names = [\"Bottle\"]\n",
    "group_filters = [\"\"]\n",
    "percentages = [1.0]\n",
    "excluded_images = set()\n",
    "class_descriptions = class_descriptions[class_descriptions['ClassName'].isin(class_names)]\n",
    "\n",
    "image_files = []\n",
    "object_dir = \"./images\"\n",
    "os.makedirs(object_dir, exist_ok=True)\n",
    "for dataset_type in [\"train\", \"validation\", \"test\"]:\n",
    "    image_dir = os.path.join(object_dir, dataset_type)\n",
    "\n",
    "    #csvのダウンロード(バカ長い)\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    annotation_file = f\"{image_dir}/{dataset_type}-annotations-bbox.csv\"\n",
    "    if not os.path.exists(annotation_file):\n",
    "        url = f\"https://storage.googleapis.com/openimages/2018_04/{dataset_type}/{dataset_type}-annotations-bbox.csv\"\n",
    "        logging.warning(f\"Download {url}.\")\n",
    "        http_download(url, annotation_file)\n",
    "\n",
    "    logging.warning(f\"Read annotation file {annotation_file}\")\n",
    "    annotations = pd.read_csv(annotation_file)\n",
    "    annotations = pd.merge(annotations, class_descriptions,left_on=\"LabelName\", right_on=\"id\",how=\"inner\")\n",
    "    annotations = annotations.loc[annotations['IsDepiction'] != 1, :] #?\n",
    "\n",
    "    filtered = []\n",
    "    for class_name, group_filter, percentage in zip(class_names, group_filters, percentages):\n",
    "        sub = annotations.loc[annotations['ClassName'] == class_name, :]\n",
    "        excluded_images |= set(sub['ImageID'].sample(frac=1 - percentage))\n",
    "\n",
    "        if group_filter == '~group':\n",
    "            excluded_images |= set(sub.loc[sub['IsGroupOf'] == 1, 'ImageID'])\n",
    "        elif group_filter == 'group':\n",
    "            excluded_images |= set(sub.loc[sub['IsGroupOf'] == 0, 'ImageID'])\n",
    "        filtered.append(sub)\n",
    "\n",
    "    annotations = pd.concat(filtered)\n",
    "    annotations = annotations.loc[~annotations['ImageID'].isin(excluded_images), :]\n",
    "\n",
    "    annotations = annotations.sample(frac=1.0)\n",
    "\n",
    "    logging.warning(f\"{dataset_type} bounding boxes size: {annotations.shape[0]}\")\n",
    "    logging.warning(\"Approximate Image Stats: \")\n",
    "    log_counts(annotations.drop_duplicates([\"ImageID\", \"ClassName\"])[\"ClassName\"])\n",
    "    logging.warning(\"Label distribution: \")\n",
    "    log_counts(annotations['ClassName'])\n",
    "\n",
    "    logging.warning(f\"Shuffle dataset.\")\n",
    "\n",
    "\n",
    "    sub_annotation_file = f\"{object_dir}/sub-{dataset_type}-annotations-bbox.csv\"\n",
    "    logging.warning(f\"Save {dataset_type} data to {sub_annotation_file}.\")\n",
    "    annotations.to_csv(sub_annotation_file, index=False)\n",
    "    image_files.extend(f\"{dataset_type}/{id}.jpg\" for id in set(annotations['ImageID']))\n",
    "logging.warning(f\"Start downloading {len(image_files)} images.\")\n",
    "batch_download(bucket, image_files, object_dir, 4, 1)\n",
    "logging.warning(\"Task Done.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nNVIDIA GeForce GTX 960\n"
     ]
    }
   ],
   "source": [
    "#確認\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make model\n",
    "from vision.ssd.mobilenetv3_ssd_lite import create_mobilenetv3_small_ssd_lite\n",
    "from vision.ssd.config import mobilenetv1_ssd_config\n",
    "create_net = lambda num: create_mobilenetv3_small_ssd_lite(num)\n",
    "config = mobilenetv1_ssd_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare tranform\n",
    "from vision.ssd.data_preprocessing import TrainAugmentation, TestTransform\n",
    "from vision.ssd.ssd import MatchPrior\n",
    "train_transform = TrainAugmentation(config.image_size, config.image_mean, config.image_std)\n",
    "target_transform = MatchPrior(config.priors, config.center_variance, config.size_variance, 0.5)\n",
    "test_transform = TestTransform(config.image_size, config.image_mean, config.image_std)\n",
    "logging.info(\"Prepare training datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optunaでカリカリにチューニングする\n",
    "Param = {\n",
    "    \"batch_size\" : 5,\n",
    "    \"base_net_lr\" : 0.001, #tune\n",
    "    \"num_epochs\" : 100,\n",
    "    \"validation_epochs\" : 5,\n",
    "    \"t_max\" : 100, #tune\n",
    "    \"lr\" : 0.01, #tune\n",
    "    \"scheduler\" : \"cosine\", #<-変えてもOK #tune\n",
    "    \"freeze_base_net\" : False, #ファインチューニングするときはTrue,\n",
    "    \"freeze_net\" : False,\n",
    "    \"num_workers\" : 0, #並列処理 windows対応してないです…\n",
    "    \"momentum\" : 0.9, #tune\n",
    "    \"weight_decay\" : 5e-4, #tune\n",
    "    \"t_max\" : 120, #tune\n",
    "    \"debug_steps\" : 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./images\"\n",
    "check_point_path = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./models\\open-images-model-labels.txt\n11136\n"
     ]
    }
   ],
   "source": [
    "from vision.utils.misc import str2bool, Timer, freeze_net_layers, store_labels\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "#TODO データセットのライブラリ作る、transformも -> OpenImagesDatasetをたたき台にする 最終的にsub-{}-annotation-bboxに統合する\n",
    "from vision.datasets.open_images import OpenImagesDataset\n",
    "\n",
    "datasets = []\n",
    "#dawnsampling\n",
    "dataset = OpenImagesDataset(dataset_path,transform=train_transform, target_transform=target_transform, dataset_type=\"train\", balance_data=True)\n",
    "label_file = os.path.join(check_point_path, \"open-images-model-labels.txt\")\n",
    "store_labels(label_file, dataset.class_names)\n",
    "logging.info(dataset)\n",
    "num_classes = len(dataset.class_names)\n",
    "\n",
    "datasets.append(dataset)\n",
    "\n",
    "num_classes = len(dataset.class_names)\n",
    "print(label_file) #models/open-images-model-labels.txtに対象載ってる\n",
    "train_dataset = ConcatDataset(datasets)\n",
    "print(len(train_dataset))\n",
    "train_loader = DataLoader(train_dataset, Param[\"batch_size\"],num_workers=Param[\"num_workers\"],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Prepare Validation datasets.\")\n",
    "val_dataset = OpenImagesDataset(dataset_path,transform=test_transform, target_transform=target_transform, dataset_type=\"test\")\n",
    "logging.info(val_dataset)\n",
    "logging.info(\"validation dataset size: {}\".format(len(val_dataset)))\n",
    "val_loader = DataLoader(val_dataset,  Param[\"batch_size\"],num_workers=Param[\"num_workers\"],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "logging.info(\"Build network.\")\n",
    "net = create_net(num_classes)\n",
    "min_loss = -10000.0\n",
    "last_epoch = -1\n",
    "base_net_lr = Param[\"base_net_lr\"]\n",
    "extra_layers_lr = Param[\"lr\"]\n",
    "if Param[\"freeze_base_net\"] == True:\n",
    "    logging.info(\"Freeze base net.\")\n",
    "    freeze_net_layers(net.base_net)\n",
    "    params = itertools.chain(net.source_layer_add_ons.parameters(), net.extras.parameters(),\n",
    "                            net.regression_headers.parameters(), net.classification_headers.parameters())\n",
    "    params = [\n",
    "        {'params': itertools.chain(\n",
    "            net.source_layer_add_ons.parameters(),\n",
    "            net.extras.parameters()\n",
    "        ), 'lr': extra_layers_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.regression_headers.parameters(),\n",
    "            net.classification_headers.parameters()\n",
    "        )}\n",
    "    ]\n",
    "elif Param[\"freeze_base_net\"] == True:\n",
    "    freeze_net_layers(net.base_net)\n",
    "    freeze_net_layers(net.source_layer_add_ons)\n",
    "    freeze_net_layers(net.extras)\n",
    "    params = itertools.chain(net.regression_headers.parameters(), net.classification_headers.parameters())\n",
    "    logging.info(\"Freeze all the layers except prediction heads.\")\n",
    "else:\n",
    "    params = [\n",
    "        {'params': net.base_net.parameters(), 'lr': base_net_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.source_layer_add_ons.parameters(),\n",
    "            net.extras.parameters()\n",
    "        ), 'lr': extra_layers_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.regression_headers.parameters(),\n",
    "            net.classification_headers.parameters()\n",
    "        )}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next モデル定義 -> 初めからやるぞ！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nif args.resume:\\n    logging.info(f\"Resume from the model {args.resume}\")\\n    net.load(args.resume)\\nelif args.base_net:\\n    logging.info(f\"Init from base net {args.base_net}\")\\n    net.init_from_base_net(args.base_net)\\nelif args.pretrained_ssd:\\n    logging.info(f\"Init from pretrained ssd {args.pretrained_ssd}\")\\n    net.init_from_pretrained_ssd(args.pretrained_ssd)\\nlogging.info(f\\'Took {timer.end(\"Load Model\"):.2f} seconds to load the model.\\')\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "#pre-train使うなら argsは頑張る\n",
    "\"\"\"\n",
    "if args.resume:\n",
    "    logging.info(f\"Resume from the model {args.resume}\")\n",
    "    net.load(args.resume)\n",
    "elif args.base_net:\n",
    "    logging.info(f\"Init from base net {args.base_net}\")\n",
    "    net.init_from_base_net(args.base_net)\n",
    "elif args.pretrained_ssd:\n",
    "    logging.info(f\"Init from pretrained ssd {args.pretrained_ssd}\")\n",
    "    net.init_from_pretrained_ssd(args.pretrained_ssd)\n",
    "logging.info(f'Took {timer.end(\"Load Model\"):.2f} seconds to load the model.')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (base_net): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): hswish()\n",
       "    (3): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (conv1): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "      (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (conv1): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "      (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "      (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(40, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "      (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (12): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "      (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (13): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "      (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (14): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (15): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): hswish()\n",
       "  )\n",
       "  (extras): ModuleList(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (classification_headers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
       "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(576, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (5): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (regression_headers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
       "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (5): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (source_layer_add_ons): ModuleList()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.nn.multibox_loss import MultiboxLoss\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR\n",
    "\n",
    "criterion = MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3,\n",
    "                             center_variance=0.1, size_variance=0.2, device=DEVICE)\n",
    "optimizer = torch.optim.SGD(params, lr=Param[\"lr\"], momentum=Param[\"momentum\"],\n",
    "                            weight_decay=Param[\"weight_decay\"])\n",
    "scheduler = CosineAnnealingLR(optimizer, Param[\"t_max\"], last_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, net, criterion, optimizer, device, debug_steps=100, epoch=-1):\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    for i, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        confidence, locations = net(images)\n",
    "        regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)  # TODO CHANGE BOXES\n",
    "        loss = regression_loss + classification_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "        if i and i % debug_steps == 0:\n",
    "            avg_loss = running_loss / debug_steps\n",
    "            avg_reg_loss = running_regression_loss / debug_steps\n",
    "            avg_clf_loss = running_classification_loss / debug_steps\n",
    "            \"\"\"\n",
    "            logging.info(\n",
    "                f\"Epoch: {epoch}, Step: {i}, \" +\n",
    "                f\"Average Loss: {avg_loss:.4f}, \" +\n",
    "                f\"Average Regression Loss {avg_reg_loss:.4f}, \" +\n",
    "                f\"Average Classification Loss: {avg_clf_loss:.4f}\"\n",
    "            )\n",
    "            \"\"\"\n",
    "            print(\"epoch: \", epoch)\n",
    "            print(\"Average Loss: \", avg_loss)\n",
    "            print(\"Average Regression Loss: \", avg_reg_loss)\n",
    "            print(\"Average Classification Loss: \", avg_clf_loss)\n",
    "            running_loss = 0.0\n",
    "            running_regression_loss = 0.0\n",
    "            running_classification_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, net, criterion, device):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    num = 0\n",
    "    for _, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "        num += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            confidence, locations = net(images)\n",
    "            regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)\n",
    "            loss = regression_loss + classification_loss\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "    return running_loss / num, running_regression_loss / num, running_classification_loss / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\naoya\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "c:\\Users\\naoya\\Desktop\\code\\pytorch-ssd\\vision\\transforms\\transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  mode = random.choice(self.sample_options)\n",
      "C:\\Users\\naoya\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9e95c7cbdd03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     train(train_loader, net, criterion, optimizer,\n\u001b[1;32m----> 4\u001b[1;33m             device=DEVICE, debug_steps=Param[\"debug_steps\"], epoch=epoch)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mParam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"validation_epochs\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mParam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_epochs\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-84a5d990eeb4>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(loader, net, criterion, optimizer, device, debug_steps, epoch)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mconfidence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mregression_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# TODO CHANGE BOXES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregression_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclassification_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\naoya\\Desktop\\code\\pytorch-ssd\\vision\\ssd\\ssd.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_net\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_layer_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mend_layer_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0madded_layer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madded_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\naoya\\Desktop\\code\\pytorch-ssd\\vision\\nn\\mobilenetv3.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mse\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\naoya\\Desktop\\code\\pytorch-ssd\\vision\\nn\\mobilenetv3.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml-agents\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1670\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1671\u001b[0m     )\n\u001b[0;32m   1672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(last_epoch + 1, Param[\"num_epochs\"]):\n",
    "    print(\"from\", last_epoch + 1, \" now : \", epoch, ' last : ', Param[\"num_epochs\"])\n",
    "    scheduler.step()\n",
    "    train(train_loader, net, criterion, optimizer,\n",
    "            device=DEVICE, debug_steps=Param[\"debug_steps\"], epoch=epoch)\n",
    "    \n",
    "    if epoch % Param[\"validation_epochs\"] == 0 or epoch == Param[\"num_epochs\"] - 1:\n",
    "        val_loss, val_regression_loss, val_classification_loss = test(val_loader, net, criterion, DEVICE)\n",
    "        logging.info(\n",
    "            f\"Epoch: {epoch}, \" +\n",
    "            f\"Validation Loss: {val_loss:.4f}, \" +\n",
    "            f\"Validation Regression Loss {val_regression_loss:.4f}, \" +\n",
    "            f\"Validation Classification Loss: {val_classification_loss:.4f}\"\n",
    "        )\n",
    "        model_path = os.path.join(check_point_path, f\"{args.net}-Epoch-{epoch}-Loss-{val_loss}.pth\")\n",
    "        net.save(model_path)\n",
    "        logging.info(f\"Saved model {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}