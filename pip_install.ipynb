{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd030e21dc3ec1938ceff07fd29576d0c36cddf01a42a134a7947f9997dd77d262c",
   "display_name": "Python 3.7.9 64-bit ('ml-agents': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "30e21dc3ec1938ceff07fd29576d0c36cddf01a42a134a7947f9997dd77d262c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.4.0+cu92 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.4.0+cu92)\n",
      "Requirement already satisfied: torchvision==0.5.0+cu92 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (0.5.0+cu92)\n",
      "Requirement already satisfied: six in c:\\users\\naoya\\appdata\\roaming\\python\\python37\\site-packages (from torchvision==0.5.0+cu92) (1.15.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from torchvision==0.5.0+cu92) (8.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from torchvision==0.5.0+cu92) (1.19.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.19.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\naoya\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.4.0+cu92 torchvision==0.5.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.19.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\naoya\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "ERROR: Could not find a version that satisfies the requirement urllib (from versions: none)\n",
      "ERROR: No matching distribution found for urllib\n",
      "Collecting multiprocessing\n",
      "  Using cached multiprocessing-2.6.2.1.tar.gz (108 kB)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\naoya\\Anaconda3\\envs\\ml-agents\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\naoya\\\\AppData\\\\Local\\\\Temp\\\\pip-install-v553bbnt\\\\multiprocessing\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\naoya\\\\AppData\\\\Local\\\\Temp\\\\pip-install-v553bbnt\\\\multiprocessing\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\naoya\\AppData\\Local\\Temp\\pip-pip-egg-info-ykipplee'\n",
      "         cwd: C:\\Users\\naoya\\AppData\\Local\\Temp\\pip-install-v553bbnt\\multiprocessing\\\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\naoya\\AppData\\Local\\Temp\\pip-install-v553bbnt\\multiprocessing\\setup.py\", line 94\n",
      "        print 'Macros:'\n",
      "                      ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print('Macros:')?\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.20.73-py2.py3-none-any.whl (7.5 MB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from botocore) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from botocore) (2.8.1)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\naoya\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.15.0)\n",
      "Installing collected packages: jmespath, botocore\n",
      "Successfully installed botocore-1.20.73 jmespath-0.10.0\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.17.73-py2.py3-none-any.whl (131 kB)\n",
      "Collecting s3transfer<0.5.0,>=0.4.0\n",
      "  Downloading s3transfer-0.4.2-py2.py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.73 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from boto3) (1.20.73)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from botocore<1.21.0,>=1.20.73->boto3) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\naoya\\anaconda3\\envs\\ml-agents\\lib\\site-packages (from botocore<1.21.0,>=1.20.73->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\naoya\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.73->boto3) (1.15.0)\n",
      "Installing collected packages: s3transfer, boto3\n",
      "Successfully installed boto3-1.17.73 s3transfer-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install multiprocessing\n",
    "!pip install botocore\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "def http_download(url, path):\n",
    "    with request.urlopen(url) as f:\n",
    "        with open(path, \"wb\") as fout:\n",
    "            buf = f.read(1024)\n",
    "            while buf:\n",
    "                fout.write(buf)\n",
    "                buf = f.read(1024)\n",
    "\n",
    "from multiprocessing import Pool, Manager\n",
    "import functools\n",
    "def batch_download(bucket, file_paths, root, num_workers=10, retry=10):\n",
    "    with Pool(num_workers) as p:\n",
    "        m = Manager()\n",
    "        counter = m.Value('i', 0)\n",
    "        lock = m.Lock()\n",
    "        download_ = functools.partial(download, bucket, root, retry, counter, lock)\n",
    "        p.map(download_, file_paths)\n",
    "\n",
    "def log_counts(values):\n",
    "    for k, count in values.value_counts().iteritems():\n",
    "        logging.warning(f\"{k}: {count}/{len(values)} = {count/len(values):.2f}.\")\n",
    "        \n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import botocore\n",
    "\n",
    "def download(bucket, root, retry, counter, lock, path):\n",
    "    i = 0\n",
    "    src = path\n",
    "    dest = f\"{root}/{path}\"\n",
    "    while i < retry:\n",
    "        try:\n",
    "            if not os.path.exists(dest):\n",
    "                s3.download_file(bucket, src, dest)\n",
    "            else:\n",
    "                logging.info(f\"{dest} already exists.\")\n",
    "            with lock:\n",
    "                counter.value += 1\n",
    "                if counter.value % 100 == 0:\n",
    "                    logging.warning(f\"Downloaded {counter.value} images.\")\n",
    "            return\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == \"404\":\n",
    "                logging.warning(f\"The file s3://{bucket}/{src} does not exist.\")\n",
    "                return\n",
    "            i += 1\n",
    "            logging.warning(f\"Sleep {i} and try again.\")\n",
    "            time.sleep(i)\n",
    "    logging.warning(f\"Failed to download the file s3://{bucket}/{src}. Exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Read annotation file ./images\\train/train-annotations-bbox.csv\n",
      "WARNING:root:train bounding boxes size: 39139\n",
      "WARNING:root:Approximate Image Stats: \n",
      "WARNING:root:Bottle: 11136/11136 = 1.00.\n",
      "WARNING:root:Label distribution: \n",
      "WARNING:root:Bottle: 39139/39139 = 1.00.\n",
      "WARNING:root:Shuffle dataset.\n",
      "WARNING:root:Save train data to ./images/sub-train-annotations-bbox.csv.\n",
      "WARNING:root:Read annotation file ./images\\validation/validation-annotations-bbox.csv\n",
      "WARNING:root:validation bounding boxes size: 336\n",
      "WARNING:root:Approximate Image Stats: \n",
      "WARNING:root:Bottle: 175/175 = 1.00.\n",
      "WARNING:root:Label distribution: \n",
      "WARNING:root:Bottle: 336/336 = 1.00.\n",
      "WARNING:root:Shuffle dataset.\n",
      "WARNING:root:Save validation data to ./images/sub-validation-annotations-bbox.csv.\n",
      "WARNING:root:Read annotation file ./images\\test/test-annotations-bbox.csv\n",
      "WARNING:root:test bounding boxes size: 957\n",
      "WARNING:root:Approximate Image Stats: \n",
      "WARNING:root:Bottle: 520/520 = 1.00.\n",
      "WARNING:root:Label distribution: \n",
      "WARNING:root:Bottle: 957/957 = 1.00.\n",
      "WARNING:root:Shuffle dataset.\n",
      "WARNING:root:Save test data to ./images/sub-test-annotations-bbox.csv.\n",
      "WARNING:root:Start downloading 11831 images.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'download' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-43f8787ef59e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mimage_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{dataset_type}/{id}.jpg\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ImageID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Start downloading {len(image_files)} images.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mbatch_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Task Done.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-21820946591a>\u001b[0m in \u001b[0;36mbatch_download\u001b[1;34m(bucket, file_paths, root, num_workers, retry)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mlock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mdownload_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'download' is not defined"
     ]
    }
   ],
   "source": [
    "#download open-images, make my own dataset!!!!\n",
    "\n",
    "bucket = \"open-images-dataset\"\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "class_description_file = './class-descriptions-boxable.csv' #bofore download CLI \n",
    "class_descriptions = pd.read_csv(class_description_file,names=[\"id\", \"ClassName\"])\n",
    "#learn bottle data\n",
    "class_names = [\"Bottle\"]\n",
    "group_filters = [\"\"]\n",
    "percentages = [1.0]\n",
    "excluded_images = set()\n",
    "class_descriptions = class_descriptions[class_descriptions['ClassName'].isin(class_names)]\n",
    "\n",
    "image_files = []\n",
    "object_dir = \"./images\"\n",
    "os.makedirs(object_dir, exist_ok=True)\n",
    "for dataset_type in [\"train\", \"validation\", \"test\"]:\n",
    "    image_dir = os.path.join(object_dir, dataset_type)\n",
    "\n",
    "    #csvのダウンロード(バカ長い)\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    annotation_file = f\"{image_dir}/{dataset_type}-annotations-bbox.csv\"\n",
    "    if not os.path.exists(annotation_file):\n",
    "        url = f\"https://storage.googleapis.com/openimages/2018_04/{dataset_type}/{dataset_type}-annotations-bbox.csv\"\n",
    "        logging.warning(f\"Download {url}.\")\n",
    "        http_download(url, annotation_file)\n",
    "\n",
    "    logging.warning(f\"Read annotation file {annotation_file}\")\n",
    "    annotations = pd.read_csv(annotation_file)\n",
    "    annotations = pd.merge(annotations, class_descriptions,left_on=\"LabelName\", right_on=\"id\",how=\"inner\")\n",
    "    annotations = annotations.loc[annotations['IsDepiction'] != 1, :] #?\n",
    "\n",
    "    filtered = []\n",
    "    for class_name, group_filter, percentage in zip(class_names, group_filters, percentages):\n",
    "        sub = annotations.loc[annotations['ClassName'] == class_name, :]\n",
    "        excluded_images |= set(sub['ImageID'].sample(frac=1 - percentage))\n",
    "\n",
    "        if group_filter == '~group':\n",
    "            excluded_images |= set(sub.loc[sub['IsGroupOf'] == 1, 'ImageID'])\n",
    "        elif group_filter == 'group':\n",
    "            excluded_images |= set(sub.loc[sub['IsGroupOf'] == 0, 'ImageID'])\n",
    "        filtered.append(sub)\n",
    "\n",
    "    annotations = pd.concat(filtered)\n",
    "    annotations = annotations.loc[~annotations['ImageID'].isin(excluded_images), :]\n",
    "\n",
    "    annotations = annotations.sample(frac=1.0)\n",
    "\n",
    "    logging.warning(f\"{dataset_type} bounding boxes size: {annotations.shape[0]}\")\n",
    "    logging.warning(\"Approximate Image Stats: \")\n",
    "    log_counts(annotations.drop_duplicates([\"ImageID\", \"ClassName\"])[\"ClassName\"])\n",
    "    logging.warning(\"Label distribution: \")\n",
    "    log_counts(annotations['ClassName'])\n",
    "\n",
    "    logging.warning(f\"Shuffle dataset.\")\n",
    "\n",
    "\n",
    "    sub_annotation_file = f\"{object_dir}/sub-{dataset_type}-annotations-bbox.csv\"\n",
    "    logging.warning(f\"Save {dataset_type} data to {sub_annotation_file}.\")\n",
    "    annotations.to_csv(sub_annotation_file, index=False)\n",
    "    image_files.extend(f\"{dataset_type}/{id}.jpg\" for id in set(annotations['ImageID']))\n",
    "logging.warning(f\"Start downloading {len(image_files)} images.\")\n",
    "batch_download(bucket, image_files, object_dir, 10, 10)\n",
    "logging.warning(\"Task Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nNVIDIA GeForce GTX 960\n"
     ]
    }
   ],
   "source": [
    "#確認\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make model\n",
    "from vision.ssd.mobilenetv3_ssd_lite import create_mobilenetv3_small_ssd_lite\n",
    "from vision.ssd.config import mobilenetv1_ssd_config\n",
    "create_net = lambda num: create_mobilenetv3_small_ssd_lite(num)\n",
    "config = mobilenetv1_ssd_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare tranform\n",
    "from vision.ssd.data_preprocessing import TrainAugmentation, TestTransform\n",
    "from vision.ssd.ssd import MatchPrior\n",
    "train_transform = TrainAugmentation(config.image_size, config.image_mean, config.image_std)\n",
    "target_transform = MatchPrior(config.priors, config.center_variance, config.size_variance, 0.5)\n",
    "test_transform = TestTransform(config.image_size, config.image_mean, config.image_std)\n",
    "logging.info(\"Prepare training datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8d8c940b1a56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#データセットのライブラリ作る、transformも\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_images\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpenImagesDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOpenImagesDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalance_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbalance_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabel_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"open-images-model-labels.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\naoya\\Desktop\\code\\pytorch-ssd\\vision\\datasets\\open_images.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "#TODO データセットのライブラリ作る、transformも\n",
    "from vision.datasets.open_images import OpenImagesDataset\n",
    "datasets = []\n",
    "dataset = OpenImagesDataset(dataset_path,transform=train_transform, target_transform=target_transform, dataset_type=\"train\", balance_data=args.balance_data)\n",
    "label_file = os.path.join(args.checkpoint_folder, \"open-images-model-labels.txt\")\n",
    "store_labels(label_file, dataset.class_names)\n",
    "logging.info(dataset)\n",
    "num_classes = len(dataset.class_names)\n",
    "\n",
    "dataset_path = object_dir\n",
    "\n",
    "dataset = OpenImagesDataset(dataset_path,transform=train_transform, target_transform=target_transform, dataset_type=\"train\", balance_data=args.balance_data)\n",
    "label_file = os.path.join(args.checkpoint_folder, \"open-images-model-labels.txt\")\n",
    "store_labels(label_file, dataset.class_names)\n",
    "logging.info(dataset)\n",
    "num_classes = len(dataset.class_names)\n",
    "logging.info(f\"Stored labels into file {label_file}.\")\n",
    "train_dataset = ConcatDataset(datasets)\n",
    "logging.info(\"Train dataset size: {}\".format(len(train_dataset)))\n",
    "train_loader = DataLoader(train_dataset, args.batch_size,num_workers=args.num_workers,shuffle=True)\n",
    "\n",
    "val_dataset = OpenImagesDataset(dataset_path,transform=test_transform, target_transform=target_transform, dataset_type=\"test\")\n",
    "logging.info(val_dataset)\n",
    "logging.info(\"validation dataset size: {}\".format(len(val_dataset)))\n",
    "val_loader = DataLoader(val_dataset, args.batch_size,num_workers=args.num_workers,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Param = {\n",
    "    \"batch_size\" : 5,\n",
    "    \"base_net_lr\" : 0.001,\n",
    "    \"num_epochs\" : 100,\n",
    "    \"validation_epochs\" : 5,\n",
    "    \"t_max\" : 100,\n",
    "    \"lr\" : 0.01,\n",
    "    \"scheduler\" : \"cosine\",\n",
    "    \"freeze_base_net\" : False #ファインチューニングするときはTrue,\n",
    "    \"freeze_net\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "logging.info(\"Build network.\")\n",
    "net = create_net(num_classes)\n",
    "min_loss = -10000.0\n",
    "last_epoch = -1\n",
    "base_net_lr = Param[\"base_net_lr\"]\n",
    "extra_layers_lr = Param[\"lr\"]\n",
    "if Param[\"freeze_base_net\"] == True:\n",
    "    logging.info(\"Freeze base net.\")\n",
    "    freeze_net_layers(net.base_net)\n",
    "    params = itertools.chain(net.source_layer_add_ons.parameters(), net.extras.parameters(),\n",
    "                            net.regression_headers.parameters(), net.classification_headers.parameters())\n",
    "    params = [\n",
    "        {'params': itertools.chain(\n",
    "            net.source_layer_add_ons.parameters(),\n",
    "            net.extras.parameters()\n",
    "        ), 'lr': extra_layers_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.regression_headers.parameters(),\n",
    "            net.classification_headers.parameters()\n",
    "        )}\n",
    "    ]\n",
    "elif Param[\"freeze_base_net\"] == True:\n",
    "    freeze_net_layers(net.base_net)\n",
    "    freeze_net_layers(net.source_layer_add_ons)\n",
    "    freeze_net_layers(net.extras)\n",
    "    params = itertools.chain(net.regression_headers.parameters(), net.classification_headers.parameters())\n",
    "    logging.info(\"Freeze all the layers except prediction heads.\")\n",
    "else:\n",
    "    params = [\n",
    "        {'params': net.base_net.parameters(), 'lr': base_net_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.source_layer_add_ons.parameters(),\n",
    "            net.extras.parameters()\n",
    "        ), 'lr': extra_layers_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.regression_headers.parameters(),\n",
    "            net.classification_headers.parameters()\n",
    "        )}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next モデル定義 -> 初めからやるぞ！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.nn.multibox_loss import MultiboxLoss\n",
    "\n",
    "criterion = MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3,\n",
    "                             center_variance=0.1, size_variance=0.2, device=DEVICE)\n",
    "optimizer = torch.optim.SGD(params, lr=args.lr, momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, net, criterion, optimizer, device, debug_steps=100, epoch=-1):\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    for i, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        confidence, locations = net(images)\n",
    "        regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)  # TODO CHANGE BOXES\n",
    "        loss = regression_loss + classification_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "        if i and i % debug_steps == 0:\n",
    "            avg_loss = running_loss / debug_steps\n",
    "            avg_reg_loss = running_regression_loss / debug_steps\n",
    "            avg_clf_loss = running_classification_loss / debug_steps\n",
    "            logging.info(\n",
    "                f\"Epoch: {epoch}, Step: {i}, \" +\n",
    "                f\"Average Loss: {avg_loss:.4f}, \" +\n",
    "                f\"Average Regression Loss {avg_reg_loss:.4f}, \" +\n",
    "                f\"Average Classification Loss: {avg_clf_loss:.4f}\"\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            running_regression_loss = 0.0\n",
    "            running_classification_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, net, criterion, device):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    num = 0\n",
    "    for _, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "        num += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            confidence, locations = net(images)\n",
    "            regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)\n",
    "            loss = regression_loss + classification_loss\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "    return running_loss / num, running_regression_loss / num, running_classification_loss / num"
   ]
  }
 ]
}